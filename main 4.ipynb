{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"elapsed":2558,"status":"error","timestamp":1682490328200,"user":{"displayName":"Aswanth","userId":"16060101675802835280"},"user_tz":-330},"id":"RWQDcFUDFAJn","outputId":"7c780c94-1aad-4bf9-f987-779a1347d9b4"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-07-04 11:45:22.819773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-07-04 11:45:23.067425: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.10/site-packages/cv2/../../lib64:\n","2023-07-04 11:45:23.067464: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2023-07-04 11:45:23.123391: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-07-04 11:45:24.582609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.10/site-packages/cv2/../../lib64:\n","2023-07-04 11:45:24.582829: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/.local/lib/python3.10/site-packages/cv2/../../lib64:\n","2023-07-04 11:45:24.582851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]},{"name":"stdout","output_type":"stream","text":["pygame 2.1.2 (SDL 2.0.16, Python 3.10.6)\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n"]}],"source":["import cv2\n","from tensorflow.keras.models import load_model \n","import numpy as np  \n","from pygame import mixer \n","import os \n","import face_recognition \n","import datetime \n","import csv \n","import time \n","import sqlite3\n","import smtplib\n","import dlib\n","from imutils import face_utils"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Yhj7TRDtFAJs","outputId":"aa3b3f24-de89-47b8-e6e5-abcaa4b987cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/user/Downloads/Project_new\n"]}],"source":["cd \"/home/user/Downloads/Project_new\"    \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Bmsm_iR7FAJt"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xSkZu4fDFAJv","outputId":"fa5419bc-1bb1-4778-c60f-beb0f1bbe711"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-07-04 11:45:31.766806: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2023-07-04 11:45:31.766965: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (user-HP-Laptop-15-bs0xx): /proc/driver/nvidia/version does not exist\n","2023-07-04 11:45:31.768057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["\n","face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n","\n","\n","model = load_model('model/model_eyes1.h5')\n","model2 = load_model('model/model_yawn1.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJKEeSHiFAJw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wWz5ffWFAJx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"88oPD3OLFAJy","outputId":"7462a209-81dc-4bd0-b574-9b86a71058e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 2s 2s/step\n","[array([36.65, 63.35], dtype=float32)]\n","Yawn\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 106ms/step\n"]},{"ename":"NameError","evalue":"name 'predictor' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 179\u001b[0m\n\u001b[1;32m    176\u001b[0m         cv2\u001b[39m.\u001b[39mrectangle(frame,(\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m),(width,height),(\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m),yawn_thicc)\n\u001b[1;32m    178\u001b[0m \u001b[39mfor\u001b[39;00m face \u001b[39min\u001b[39;00m faces:\n\u001b[0;32m--> 179\u001b[0m                 shape \u001b[39m=\u001b[39m predictor(gray, face)\n\u001b[1;32m    180\u001b[0m                 shape \u001b[39m=\u001b[39m face_utils\u001b[39m.\u001b[39mshape_to_np(shape)\n\u001b[1;32m    182\u001b[0m                 mouth_landmarks \u001b[39m=\u001b[39m shape[\u001b[39m48\u001b[39m:\u001b[39m68\u001b[39m]  \u001b[39m# Extract the mouth landmarks (indices 48-67)\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"]}],"source":["\n","mixer.init()\n","sound= mixer.Sound(r'/home/user/Downloads/Project_new/alarm.wav')\n","cap = cv2.VideoCapture(0)\n","\n","eye_score = 0\n","eye_thicc=2\n","yawn_score = 0\n","yawn_thicc=2\n","eye_counter=0\n","yawn_counter=0\n","font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n","\n","\n","# Load images and labels for face recognition\n","known_face_encodings = []\n","known_face_labels = []\n","\n","\n","img_path_1 = \"/home/user/Downloads/Project_new/Training_images/Ajnas.jpg\"\n","img_path_2 = \"/home/user/Downloads/Project_new/Training_images/Aswanth_A.jpg\"\n","\n","img_1 = cv2.imread(img_path_1)\n","img_2 = cv2.imread(img_path_2)\n","\n","\n","label_1 = \"Ajnas\"\n","label_2 = \"Aswanth A\"\n","\n","\n","known_face_encodings.append(face_recognition.face_encodings(img_1)[0])\n","known_face_encodings.append(face_recognition.face_encodings(img_2)[0])\n","\n","known_face_labels = [label_1, label_2]\n","\n","# Create CSV file and headers\n","with open('data.csv', mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerow(['Name', 'Eye Status', 'Yawn Status', 'Time'])\n","\n","\n","\n","def send_email():\n","    sender_email = \"touristbusdriver1@gmail.com\"\n","    receiver_email = \"touristbusadmi@gmail.com\"\n","    password = \"grww etbe bonf lpox\"\n","\n","    subject = \"Alert!\"\n","    message = \"The alert sound is continuously playing the driver getting drowsy.\"\n","\n","    try:\n","        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n","        server.starttls()\n","        server.login(sender_email, password)\n","        server.sendmail(sender_email, receiver_email, f\"Subject: {subject}\\n\\n{message}\")\n","        print(\"Email sent successfully\")\n","    except Exception as e:\n","        print(f\"Error: {str(e)}\")\n","    finally:\n","        server.quit()\n","\n","\n","\n","while True:\n","        ret, frame = cap.read()\n","        height,width = frame.shape[0:2]\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    #COLOR_BGR2GRAY\n","        faces= face_cascade.detectMultiScale(gray, scaleFactor= 1.2, minNeighbors=3)\n","        eyes= eye_cascade.detectMultiScale(gray, scaleFactor= 1.1, minNeighbors=1)\n","        \n","        cv2.rectangle(frame, (0,height-50),(200,height),(0,0,0),thickness=cv2.FILLED)\n","\n","\n","        \n","         # Detect faces in the frame\n","        face_locations = face_recognition.face_locations(frame)\n","        face_encodings = face_recognition.face_encodings(frame, face_locations)\n","\n","\n","        # Loop over the detected faces and draw a rectangle around them\n","        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n","            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n","            name = \"Unknown\"\n","\n","            # Check if the detected face matches with any of the known faces\n","            if True in matches:\n","                first_match_index = matches.index(True)\n","                name = known_face_labels[first_match_index]\n","\n","            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n","            cv2.putText(frame, name, (left, top - 6), font, 0.5, (0, 0, 255), 2)\n","       \n","\n","        \n","        def calculate_mouth_aspect_ratio(shape):\n","                left_mouth = shape[48:60]  # Indices of the left mouth landmarks\n","                right_mouth = shape[60:68]  # Indices of the right mouth landmarks\n","\n","                # Calculate the distances between the mouth landmarks\n","                left_distance = np.mean(np.abs(left_mouth[1:] - left_mouth[:-1]))\n","                right_distance = np.mean(np.abs(right_mouth[1:] - right_mouth[:-1]))\n","\n","                # Calculate the mouth aspect ratio\n","                mouth_aspect_ratio = (left_distance + right_distance) / (2 * mouth_width)\n","\n","\n","                return mouth_aspect_ratio\n","\n","\n","        for (x,y,w,h) in faces:\n","                cv2.rectangle(frame,pt1=(x,y),pt2=(x+w,y+h), color= (255,0,0),thickness=3 )\n","                mouth= frame[y:y+h, x:x+w]\n","                mouth= cv2.resize(mouth,(80, 80))\n","                mouth= mouth/255\n","                mouth=mouth.reshape(80, 80,3)\n","                mouth= np.expand_dims(mouth,axis=0)\n","                # preprocessing is done now model prediction\n","                yawn_prediction = model2.predict(mouth)\n","                print([np.round(x*100, 2) for x in yawn_prediction])\n","                # print(prediction)\n","                if yawn_prediction[0][0]<yawn_prediction[0][1]:\n","                        yawn_score=yawn_score+1\n","                        print(\"Yawn\")\n","                        yawn_status = \"Yawn\"\n","                        cv2.putText(frame,'Yawn',(10,height-380),fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,fontScale=1,color=(0,0,255), thickness=1,lineType=cv2.LINE_AA)\n","                else:\n","                        yawn_score=yawn_score-1\n","                        print(\"No Yawn\")\n","                        yawn_status = \"No_Yawn\"\n","                        cv2.putText(frame,'No Yawn',(10,height-380),fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,fontScale=1,color=(0,0,255),thickness=1,lineType=cv2.LINE_AA)\n","\n","\n","        for (ex,ey,ew,eh) in eyes:  \n","                cv2.rectangle(frame,pt1=(ex,ey),pt2=(ex+ew,ey+eh), color=(255,0,0), thickness=3 )\n","                # preprocessing steps\n","                eye= frame[ey:ey+eh,ex:ex+ew]\n","                eye= cv2.resize(eye,(80,80))\n","                eye= eye/255\n","                eye= eye.reshape(80,80,3)\n","                eye= np.expand_dims(eye,axis=0)\n","                # preprocessing is done now model prediction\n","                eye_prediction = model.predict(eye)\n","                #print(eye_prediction)\n","                # if eyes are closed\n","                if eye_prediction[0][0]>0.8:\n","                        eye_score=eye_score+1\n","                        eye_status = \"Closed\"\n","                        cv2.putText(frame,'closed',(10,height-20),fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,fontScale=1,color=(255,255,255 ),thickness=1,lineType=cv2.LINE_AA)\n","                # if eyes are open\n","                else:\n","                        eye_score=eye_score-1\n","                        eye_status = \"Open\"\n","                        cv2.putText(frame,'open',(10,height-20),fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,fontScale=1,color=(255,255,255),thickness=1,lineType=cv2.LINE_AA)  \n","\n","        if(yawn_score<0):\n","                        yawn_score=0\n","        cv2.putText(frame,'Score:'+str(yawn_score),(150,height-380), font,1,(0,0,255),1,cv2.LINE_AA)\n","        cv2.putText(frame,'Counter_y:'+str(int(yawn_counter/5)),(400,height-380), font, 1,(0,0,255),1,cv2.LINE_AA)\n","        if(yawn_score>7):\n","                #person is feeling sleepy so we beep the alarm\n","                if(yawn_counter/7>=3):\n","                        yawn_counter=0\n","                       \n","                try:\n","                        sound.play()\n","                        send_email()\n","                        yawn_counter+=1\n","                except: # isplaying = False\n","                        pass\n","                if(yawn_thicc<8):\n","                        yawn_thicc= yawn_thicc+2\n","                else:\n","                        yawn_thicc=yawn_thicc-2\n","                        if(yawn_thicc<2):\n","                                yawn_thicc=2\n","                cv2.rectangle(frame,(0,0),(width,height),(0,0,255),yawn_thicc)\n","\n","        for face in faces:\n","                        shape = predictor(gray, face)\n","                        shape = face_utils.shape_to_np(shape)\n","\n","                        mouth_landmarks = shape[48:68]  # Extract the mouth landmarks (indices 48-67)\n","                        mouth_aspect_ratio = calculate_mouth_aspect_ratio(mouth_landmarks)\n","\n","        \n","\n","        if(eye_score<0):\n","                        eye_score=0\n","        cv2.putText(frame,'Score:'+str(eye_score),(100,height-20), font,1,(255,255,255),1,cv2.LINE_AA)\n","        cv2.putText(frame,'Counter_e:'+str(int(eye_counter/9)),(400,height-20), font, 1,(0,0,255),1,cv2.LINE_AA)\n","        if(eye_score>15):\n","                #person is feeling sleepy so we beep the alarm\n","                if(eye_counter/8>=3):\n","                        eye_counter=0\n","                       \n","                try:\n","                        sound.play()\n","                        time.sleep(10)\n","                        send_email()\n","                        eye_counter+=1\n","\n","                except: # isplaying = False\n","                        pass\n","                if(eye_thicc<15):\n","                        eye_thicc= eye_thicc+2\n","                else:\n","                        eye_thicc=eye_thicc-2\n","                        if(eye_thicc<2):\n","                                eye_thicc=2\n","                                \n","                cv2.rectangle(frame,(0,0),(width,height),(0,0,255),eye_thicc)               \n","        cv2.imshow('frame',frame)\n","        if cv2.waitKey(33) & 0xFF==ord('q'):\n","                break\n","\n","         # Get current time\n","        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","\n","            # Save data in CSV file\n","        with open('data.csv', mode='a', newline='') as file:\n","                writer = csv.writer(file)\n","                writer.writerow([name,eye_status, yawn_status, current_time])     \n","\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2HmBGRB-FAJ4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswanthoffl/DDD-Project/blob/main/Model%20Training/Drowsy_Yawn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtgNXw91szdZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout,Input,Flatten,Dense,MaxPooling2D \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf1uKpIftQuR",
        "outputId": "bd9e5e30-067a-46c2-a330-eaa9111f6b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA_OqdoptcBk",
        "outputId": "53ad4392-3be9-45cd-b413-59a2e0e845ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/EY_Dataset/dataset_new/yawn_dataset\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/EY_Dataset/dataset_new/yawn_dataset' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb1lcLobtsRz",
        "outputId": "c63d0586-4a75-4816-ee9b-dc6fcc0b7d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 987 images belonging to 2 classes.\n",
            "Found 246 images belonging to 2 classes.\n",
            "Found 215 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "batchsize=32\n",
        "train_datagen= ImageDataGenerator(rescale=1./255, rotation_range=0.2,shear_range=0.2,zoom_range=0.2,width_shift_range=0.2,height_shift_range=0.2, validation_split=0.2)\n",
        "train_data= train_datagen.flow_from_directory(r'train',target_size=(80,80),batch_size=batchsize,class_mode='categorical',subset='training' )\n",
        "validation_data= train_datagen.flow_from_directory(r'train',target_size=(80,80),batch_size=batchsize,class_mode='categorical', subset='validation')\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_data = test_datagen.flow_from_directory(r'test',target_size=(80,80),batch_size=batchsize,class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1dMBjYjwKBb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load the pre-trained InceptionV3 model without the top layers\n",
        "bmodel = InceptionV3(include_top=False, weights='imagenet', input_tensor=Input(shape=(80,80,3)))\n",
        "hmodel = bmodel.output\n",
        "hmodel = Flatten()(hmodel)\n",
        "hmodel = Dense(64, activation='relu')(hmodel)\n",
        "hmodel = Dropout(0.5)(hmodel)\n",
        "hmodel = Dense(2,activation= 'softmax')(hmodel)\n",
        "\n",
        "# Add new dense layers on top of the pre-trained model\n",
        "model = Model(inputs=bmodel.input, outputs= hmodel)\n",
        "for layer in bmodel.layers:\n",
        "        layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcEniv4rwyWn"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau,TensorBoard\n",
        "checkpoint = ModelCheckpoint(r'models/model_yawn4.h5',monitor='val_loss',save_best_only=True,verbose=3)\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', patience=20, verbose=3, restore_best_weights=True)\n",
        "learning_rate = ReduceLROnPlateau(monitor= 'val_loss', patience=10, verbose= 3 )\n",
        "tensor_board= TensorBoard(r'Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "callbacks=[checkpoint,earlystop,learning_rate,tensor_board]\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNInnN8_xIE8",
        "outputId": "c9424237-db48-40b9-d01c-61da995f57a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.6723\n",
            "Epoch 1: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 29s 958ms/step - loss: 0.5751 - accuracy: 0.6723 - val_loss: 0.6388 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 2/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.6859\n",
            "Epoch 2: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 22s 741ms/step - loss: 0.5617 - accuracy: 0.6859 - val_loss: 0.6553 - val_accuracy: 0.5759 - lr: 1.0000e-05\n",
            "Epoch 3/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.6859\n",
            "Epoch 3: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 24s 789ms/step - loss: 0.5666 - accuracy: 0.6859 - val_loss: 0.6288 - val_accuracy: 0.6562 - lr: 1.0000e-05\n",
            "Epoch 4/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.6921\n",
            "Epoch 4: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 23s 759ms/step - loss: 0.5649 - accuracy: 0.6921 - val_loss: 0.6602 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
            "Epoch 5/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.6461\n",
            "Epoch 5: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 29s 961ms/step - loss: 0.5857 - accuracy: 0.6461 - val_loss: 0.6597 - val_accuracy: 0.5893 - lr: 1.0000e-05\n",
            "Epoch 6/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.6775\n",
            "Epoch 6: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 29s 964ms/step - loss: 0.5723 - accuracy: 0.6775 - val_loss: 0.6488 - val_accuracy: 0.6295 - lr: 1.0000e-05\n",
            "Epoch 7/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.6921\n",
            "Epoch 7: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 24s 796ms/step - loss: 0.5644 - accuracy: 0.6921 - val_loss: 0.6469 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
            "Epoch 8/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.6785\n",
            "Epoch 8: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 24s 787ms/step - loss: 0.5611 - accuracy: 0.6785 - val_loss: 0.6467 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
            "Epoch 9/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.7079\n",
            "Epoch 9: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 24s 796ms/step - loss: 0.5501 - accuracy: 0.7079 - val_loss: 0.6681 - val_accuracy: 0.5580 - lr: 1.0000e-05\n",
            "Epoch 10/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.6827\n",
            "Epoch 10: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 25s 824ms/step - loss: 0.5631 - accuracy: 0.6827 - val_loss: 0.6368 - val_accuracy: 0.6116 - lr: 1.0000e-05\n",
            "Epoch 11/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.6942\n",
            "Epoch 11: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 24s 809ms/step - loss: 0.5621 - accuracy: 0.6942 - val_loss: 0.6545 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
            "Epoch 12/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5713 - accuracy: 0.6702\n",
            "Epoch 12: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 24s 791ms/step - loss: 0.5713 - accuracy: 0.6702 - val_loss: 0.6631 - val_accuracy: 0.5536 - lr: 1.0000e-05\n",
            "Epoch 13/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.6796\n",
            "Epoch 13: val_loss did not improve from 0.61506\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "30/30 [==============================] - 24s 777ms/step - loss: 0.5638 - accuracy: 0.6796 - val_loss: 0.6593 - val_accuracy: 0.6205 - lr: 1.0000e-05\n",
            "Epoch 14/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.6827\n",
            "Epoch 14: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 25s 831ms/step - loss: 0.5746 - accuracy: 0.6827 - val_loss: 0.6688 - val_accuracy: 0.5804 - lr: 1.0000e-06\n",
            "Epoch 15/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5545 - accuracy: 0.6848\n",
            "Epoch 15: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 29s 959ms/step - loss: 0.5545 - accuracy: 0.6848 - val_loss: 0.6484 - val_accuracy: 0.6295 - lr: 1.0000e-06\n",
            "Epoch 16/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.6733\n",
            "Epoch 16: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 23s 782ms/step - loss: 0.5664 - accuracy: 0.6733 - val_loss: 0.6538 - val_accuracy: 0.5759 - lr: 1.0000e-06\n",
            "Epoch 17/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.6901\n",
            "Epoch 17: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 23s 779ms/step - loss: 0.5626 - accuracy: 0.6901 - val_loss: 0.6354 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 18/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.6712\n",
            "Epoch 18: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 23s 777ms/step - loss: 0.5653 - accuracy: 0.6712 - val_loss: 0.6549 - val_accuracy: 0.6161 - lr: 1.0000e-06\n",
            "Epoch 19/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5741 - accuracy: 0.6911\n",
            "Epoch 19: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 23s 755ms/step - loss: 0.5741 - accuracy: 0.6911 - val_loss: 0.6415 - val_accuracy: 0.6161 - lr: 1.0000e-06\n",
            "Epoch 20/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.7058\n",
            "Epoch 20: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 23s 757ms/step - loss: 0.5472 - accuracy: 0.7058 - val_loss: 0.6510 - val_accuracy: 0.6205 - lr: 1.0000e-06\n",
            "Epoch 21/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.6932\n",
            "Epoch 21: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 25s 811ms/step - loss: 0.5614 - accuracy: 0.6932 - val_loss: 0.6636 - val_accuracy: 0.5804 - lr: 1.0000e-06\n",
            "Epoch 22/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.6984\n",
            "Epoch 22: val_loss did not improve from 0.61506\n",
            "30/30 [==============================] - 28s 957ms/step - loss: 0.5585 - accuracy: 0.6984 - val_loss: 0.6613 - val_accuracy: 0.5893 - lr: 1.0000e-06\n",
            "Epoch 23/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.6995\n",
            "Epoch 23: val_loss did not improve from 0.61506\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "30/30 [==============================] - 28s 957ms/step - loss: 0.5563 - accuracy: 0.6995 - val_loss: 0.6515 - val_accuracy: 0.5982 - lr: 1.0000e-06\n",
            "Epoch 23: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_data,steps_per_epoch=train_data.samples//batchsize,validation_data=validation_data,validation_steps=validation_data.samples//batchsize,callbacks=callbacks,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjJiTGTHxbTN",
        "outputId": "50f46c91-4aaa-43d9-88d9-db86cebc9bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 41s 8s/step - loss: 0.6021 - accuracy: 0.6042\n",
            "Test accuracy: 0.6041666865348816\n"
          ]
        }
      ],
      "source": [
        "test_accuracy = model.evaluate(test_data, steps=test_data.samples // batchsize) \n",
        "print(\"Test accuracy:\", test_accuracy[1]) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lmyteUN_U7m3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQMfIAmR1RGP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "adam =67.1   ----  65.1  \n",
        "nadam = 66.6\n",
        "adadelta=65.1\n",
        "rmsprop = 63.5\n",
        "SGD=62.5\n",
        "adagrad=60.4\n",
        "\n",
        "'''\n",
        "'''\n",
        "relu = \"65.1\" 64.05 \n",
        "sigmoid=\"63.54\"\n",
        "tanh=60.4\n",
        "LeakyRelu =55.7\n",
        "'''\n",
        "'''\n",
        "binary_cross with relu =59.3\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxZUJH5_eGzT"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI9GXjUPe4N8",
        "outputId": "f6a0f394-6984-42cd-a7b4-e304bdaeb4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "No Yawn detected with score: 0.85215604\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model \n",
        "model = load_model('/content/drive/MyDrive/EY_Dataset/dataset_new/yawn_dataset/models/model_yawn1.h5')\n",
        "\n",
        "\n",
        "# Define the image size\n",
        "IMAGE_SIZE = (80, 80)\n",
        "\n",
        "# Load the image and preprocess it\n",
        "mouth = cv2.imread('/content/drive/MyDrive/EY_Dataset/dataset_new/yawn_dataset/test/no_yawn/2090.jpg')\n",
        "mouth= cv2.resize(mouth,(80, 80))\n",
        "mouth= mouth/255\n",
        "mouth=mouth.reshape(80, 80,3)\n",
        "mouth= np.expand_dims(mouth,axis=0)\n",
        "# preprocessing is done now model prediction\n",
        "pred= model.predict(mouth)\n",
        "\n",
        "\n",
        "\n",
        "if pred[0][1] > pred[0][0]:\n",
        "    print('Yawn detected with score:', pred[0][1])\n",
        "else:\n",
        "    print('No Yawn detected with score:', pred[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw_QcxuGfflv",
        "outputId": "fc5c22f6-9ff5-406a-92cc-6f6d46bfbd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 6s 499ms/step - loss: 0.6341 - accuracy: 0.6098\n",
            "Validation accuracy: 0.6097561120986938\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/EY_Dataset/dataset_new/yawn_dataset/models/model_yawn1.h5')\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "val_loss, val_acc = model.evaluate(validation_data)\n",
        "\n",
        "# Print the validation accuracy\n",
        "print('Validation accuracy:', val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uaoXj9WqmAqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYetV0WpgO9B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLlFDeoHhzCc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14n4C8xXqf-PgWQo41zG2STcCZSiP5_Xb",
      "authorship_tag": "ABX9TyMCW+L3C6eJngUM3zaycYiI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
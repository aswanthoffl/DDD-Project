{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GiglVsnOt_a6F6YwEPvAvQ3N9tma5Khs",
      "authorship_tag": "ABX9TyMtcS55qYh2gX6Z3vkcCF97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswanthoffl/DDD-Project/blob/main/Model%20Training/Drowsy_eye.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9t0nueFqnj-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout,Input,Flatten,Dense,MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "metadata": {
        "id": "QfzOw2WEzA9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/EY_Dataset/dataset_new/Eye_dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz0C6_jny9AI",
        "outputId": "740f230e-6942-44c8-b217-435d6cab58d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/EY_Dataset/dataset_new/Eye_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize=32\n",
        "train_datagen= ImageDataGenerator(rescale=1./255, rotation_range=0.2,shear_range=0.2,zoom_range=0.2,width_shift_range=0.2,height_shift_range=0.2, validation_split=0.2)\n",
        "train_data= train_datagen.flow_from_directory(r'train',target_size=(80,80),batch_size=batchsize,class_mode='categorical',subset='training' )\n",
        "validation_data= train_datagen.flow_from_directory(r'train',target_size=(80,80),batch_size=batchsize,class_mode='categorical', subset='validation')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_data = test_datagen.flow_from_directory(r'test',target_size=(80,80),batch_size=batchsize,class_mode='categorical')"
      ],
      "metadata": {
        "id": "lY3KXcJh1t8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2d3bdf-e14f-46b7-ad56-7df8a9b2104a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 988 images belonging to 2 classes.\n",
            "Found 246 images belonging to 2 classes.\n",
            "Found 218 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained InceptionV3 model without the top layers\n",
        "bmodel = InceptionV3(include_top=False, weights='imagenet', input_tensor=Input(shape=(80,80,3)))\n",
        "\n",
        "# Add new dense layers on top of the pre-trained model\n",
        "hmodel = bmodel.output\n",
        "hmodel = Flatten()(hmodel)\n",
        "hmodel = Dense(64, activation='relu')(hmodel)\n",
        "hmodel = Dropout(0.5)(hmodel)\n",
        "hmodel = Dense(2,activation= 'softmax')(hmodel)\n",
        "\n",
        "model = Model(inputs=bmodel.input, outputs= hmodel)\n",
        "for layer in bmodel.layers:\n",
        "        layer.trainable = False"
      ],
      "metadata": {
        "id": "gMIj20kDgOBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd9b1d8-d490-4bcc-cb43-c59b928d53c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau,TensorBoard\n",
        "checkpoint = ModelCheckpoint(r'models/model_eyes1.h5',monitor='val_loss',save_best_only=True,verbose=2)\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', patience=7, verbose=2, restore_best_weights=True)\n",
        "learning_rate = ReduceLROnPlateau(monitor= 'val_loss', patience=3, verbose= 2 )\n",
        "tensor_board= TensorBoard(r'Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "callbacks=[checkpoint,earlystop,learning_rate,tensor_board]\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hh5CmBOQhOtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,steps_per_epoch=train_data.samples//batchsize,validation_data=validation_data,validation_steps=validation_data.samples//batchsize,callbacks=callbacks,epochs=300)"
      ],
      "metadata": {
        "id": "Gl-lX1xQhO7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cf5a30-1283-436f-a07a-58b40883057d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8462 \n",
            "Epoch 1: val_loss improved from inf to 0.22003, saving model to models/model_eyes1.h5\n",
            "30/30 [==============================] - 420s 14s/step - loss: 0.3891 - accuracy: 0.8462 - val_loss: 0.2200 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9425\n",
            "Epoch 2: val_loss improved from 0.22003 to 0.17988, saving model to models/model_eyes1.h5\n",
            "30/30 [==============================] - 23s 766ms/step - loss: 0.2017 - accuracy: 0.9425 - val_loss: 0.1799 - val_accuracy: 0.9330 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9435\n",
            "Epoch 3: val_loss improved from 0.17988 to 0.13476, saving model to models/model_eyes1.h5\n",
            "30/30 [==============================] - 23s 761ms/step - loss: 0.1720 - accuracy: 0.9435 - val_loss: 0.1348 - val_accuracy: 0.9420 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9467\n",
            "Epoch 4: val_loss improved from 0.13476 to 0.11646, saving model to models/model_eyes1.h5\n",
            "30/30 [==============================] - 22s 742ms/step - loss: 0.1478 - accuracy: 0.9467 - val_loss: 0.1165 - val_accuracy: 0.9732 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9623\n",
            "Epoch 5: val_loss did not improve from 0.11646\n",
            "30/30 [==============================] - 27s 899ms/step - loss: 0.1152 - accuracy: 0.9623 - val_loss: 0.1527 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9613\n",
            "Epoch 6: val_loss did not improve from 0.11646\n",
            "30/30 [==============================] - 21s 702ms/step - loss: 0.1015 - accuracy: 0.9613 - val_loss: 0.1873 - val_accuracy: 0.9286 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9623\n",
            "Epoch 7: val_loss improved from 0.11646 to 0.09567, saving model to models/model_eyes1.h5\n",
            "30/30 [==============================] - 22s 728ms/step - loss: 0.1108 - accuracy: 0.9623 - val_loss: 0.0957 - val_accuracy: 0.9554 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9550\n",
            "Epoch 8: val_loss did not improve from 0.09567\n",
            "30/30 [==============================] - 21s 699ms/step - loss: 0.1258 - accuracy: 0.9550 - val_loss: 0.1009 - val_accuracy: 0.9732 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9592\n",
            "Epoch 9: val_loss did not improve from 0.09567\n",
            "30/30 [==============================] - 21s 697ms/step - loss: 0.1104 - accuracy: 0.9592 - val_loss: 0.1331 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9665\n",
            "Epoch 10: val_loss did not improve from 0.09567\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "30/30 [==============================] - 21s 707ms/step - loss: 0.1073 - accuracy: 0.9665 - val_loss: 0.2137 - val_accuracy: 0.9286 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9665\n",
            "Epoch 11: val_loss did not improve from 0.09567\n",
            "30/30 [==============================] - 26s 883ms/step - loss: 0.1010 - accuracy: 0.9665 - val_loss: 0.1903 - val_accuracy: 0.9241 - lr: 1.0000e-04\n",
            "Epoch 12/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9644\n",
            "Epoch 12: val_loss did not improve from 0.09567\n",
            "30/30 [==============================] - 23s 783ms/step - loss: 0.0954 - accuracy: 0.9644 - val_loss: 0.1421 - val_accuracy: 0.9420 - lr: 1.0000e-04\n",
            "Epoch 13/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9728\n",
            "Epoch 13: val_loss did not improve from 0.09567\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "30/30 [==============================] - 21s 693ms/step - loss: 0.0893 - accuracy: 0.9728 - val_loss: 0.1060 - val_accuracy: 0.9688 - lr: 1.0000e-04\n",
            "Epoch 14/300\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9676\n",
            "Epoch 14: val_loss did not improve from 0.09567\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "30/30 [==============================] - 22s 706ms/step - loss: 0.0928 - accuracy: 0.9676 - val_loss: 0.1532 - val_accuracy: 0.9330 - lr: 1.0000e-05\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = model.evaluate(test_data, steps=test_data.samples // batchsize)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VOV3plbpV4L",
        "outputId": "2f094ddb-9fc1-4083-b018-baff3f8de058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 52s 10s/step - loss: 0.0466 - accuracy: 0.9896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test accuracy:\", test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfMQdLBzumv1",
        "outputId": "6e951b39-164f-4926-d442-c6d6b4d923c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9895833134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "adam= 98.4 -------- 98.9\n",
        "nadam=97.9\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "HXsCJWlWv03Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wHxfu4QXP7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/drive/MyDrive/EY_Dataset/dataset_new/Eye_dataset/models/model_eyes1.h5')\n",
        "\n",
        "# Define the image size\n",
        "IMAGE_SIZE = (80, 80)\n",
        "\n",
        "# Load the image and preprocess it\n",
        "img = cv2.imread('/content/drive/MyDrive/EY_Dataset/dataset_new/Eye_dataset/test/Closed/_132.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, IMAGE_SIZE)\n",
        "img = img.reshape(1, 80,80, 3)\n",
        "img = img / 255.0\n",
        "\n",
        "# Make the prediction\n",
        "pred = model.predict(img)\n",
        "\n",
        "# Print the prediction\n",
        "if pred[0][0] > pred[0][1]:\n",
        "    print('Eye is closed')\n",
        "else:\n",
        "    print('Eye is open')\n",
        "\n",
        "\n",
        "\n",
        "# Print the prediction score for each class\n",
        "print(f'Closed eye score: {pred[0][0]}')\n",
        "print(f'Open eye score: {pred[0][1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP23_toeXqLp",
        "outputId": "688cbf46-7fff-40c6-e846-d4d0067f431c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Eye is closed\n",
            "Closed eye score: 0.999937891960144\n",
            "Open eye score: 6.210152059793472e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/EY_Dataset/dataset_new/Eye_dataset/models/model_eyes1.h5')"
      ],
      "metadata": {
        "id": "fPjqPOKCdZY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation data\n",
        "val_loss, val_acc = model.evaluate(validation_data)\n",
        "\n",
        "# Print the validation accuracy\n",
        "print('Validation accuracy:', val_acc)\n"
      ],
      "metadata": {
        "id": "rVOUMdY6iVCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec700679-2147-48af-993c-784e113bc521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 31s 4s/step - loss: 0.1219 - accuracy: 0.9431\n",
            "Validation accuracy: 0.9430894255638123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oLqRH4jM8FhF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}